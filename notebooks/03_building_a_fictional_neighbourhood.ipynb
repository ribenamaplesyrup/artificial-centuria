{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# 03 - Building a Fictional Neighbourhood\n",
    "\n",
    "This notebook generates 100 synthetic personas for the Testing space before it happens experiment.\n",
    "\n",
    "**Scenario:** 42 households surrounding a 0.3-acre plot in Dalston, East London (E8) have formed a Community Land Trust. We need to simulate ~100 residents with realistic demographics and household structures.\n",
    "\n",
    "**Pipeline:**\n",
    "1. Define target demographics based on E8 census data\n",
    "2. Generate street layout and addresses\n",
    "3. Allocate household types to addresses\n",
    "4. Generate people within each household\n",
    "5. Add individuation (personality, attitudes, data files)\n",
    "6. Validate and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional\n",
    "import uuid\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from centuria.llm import complete, estimate_cost, CostEstimate\n",
    "from centuria.persona import create_persona, generate_synthetic_files, SyntheticIdentity\n",
    "from centuria.data import process_personal_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographics-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Demographics Definition\n",
    "\n",
    "Define target distributions based on E8 Dalston demographics. These are approximations informed by census data and the area's character as a gentrifying inner-London neighbourhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demographics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographics validated. Target distributions:\n",
      "\n",
      "household_types:\n",
      "  single_person: 30%\n",
      "  couple_no_children: 20%\n",
      "  family_with_children: 25%\n",
      "  house_share: 15%\n",
      "  multi_generational: 10%\n",
      "\n",
      "tenure:\n",
      "  owner_occupied: 35%\n",
      "  private_rented: 35%\n",
      "  social_housing: 30%\n",
      "\n",
      "ethnicity:\n",
      "  white_british: 30%\n",
      "  white_other: 15%\n",
      "  black_british_caribbean: 12%\n",
      "  black_british_african: 10%\n",
      "  turkish_kurdish: 12%\n",
      "  south_asian: 8%\n",
      "  east_asian: 5%\n",
      "  mixed: 8%\n",
      "\n",
      "age_brackets:\n",
      "  18-24: 12%\n",
      "  25-34: 28%\n",
      "  35-44: 22%\n",
      "  45-54: 15%\n",
      "  55-64: 12%\n",
      "  65+: 11%\n",
      "\n",
      "socioeconomic:\n",
      "  working_class: 35%\n",
      "  lower_middle: 25%\n",
      "  middle_class: 25%\n",
      "  professional: 15%\n",
      "\n",
      "years_in_area:\n",
      "  0-2: 20%\n",
      "  3-5: 20%\n",
      "  6-10: 15%\n",
      "  11-20: 20%\n",
      "  20+: 25%\n"
     ]
    }
   ],
   "source": [
    "# E8 Dalston Target Demographics\n",
    "# Based on 2021 Census and local knowledge of gentrification patterns\n",
    "\n",
    "DEMOGRAPHICS = {\n",
    "    # Household composition (must sum to 1.0)\n",
    "    \"household_types\": {\n",
    "        \"single_person\": 0.30,\n",
    "        \"couple_no_children\": 0.20,\n",
    "        \"family_with_children\": 0.25,\n",
    "        \"house_share\": 0.15,\n",
    "        \"multi_generational\": 0.10,\n",
    "    },\n",
    "    \n",
    "    # Tenure distribution\n",
    "    \"tenure\": {\n",
    "        \"owner_occupied\": 0.35,\n",
    "        \"private_rented\": 0.35,\n",
    "        \"social_housing\": 0.30,\n",
    "    },\n",
    "    \n",
    "    # Ethnicity (E8 is highly diverse)\n",
    "    \"ethnicity\": {\n",
    "        \"white_british\": 0.30,\n",
    "        \"white_other\": 0.15,  # European migrants\n",
    "        \"black_british_caribbean\": 0.12,\n",
    "        \"black_british_african\": 0.10,\n",
    "        \"turkish_kurdish\": 0.12,  # Large local community\n",
    "        \"south_asian\": 0.08,\n",
    "        \"east_asian\": 0.05,\n",
    "        \"mixed\": 0.08,\n",
    "    },\n",
    "    \n",
    "    # Age distribution (skews younger than UK average)\n",
    "    \"age_brackets\": {\n",
    "        \"18-24\": 0.12,\n",
    "        \"25-34\": 0.28,\n",
    "        \"35-44\": 0.22,\n",
    "        \"45-54\": 0.15,\n",
    "        \"55-64\": 0.12,\n",
    "        \"65+\": 0.11,\n",
    "    },\n",
    "    \n",
    "    # Socioeconomic (reflects gentrification mix)\n",
    "    \"socioeconomic\": {\n",
    "        \"working_class\": 0.35,\n",
    "        \"lower_middle\": 0.25,\n",
    "        \"middle_class\": 0.25,\n",
    "        \"professional\": 0.15,\n",
    "    },\n",
    "    \n",
    "    # Years in area (gentrification creates bimodal distribution)\n",
    "    \"years_in_area\": {\n",
    "        \"0-2\": 0.20,   # Recent arrivals\n",
    "        \"3-5\": 0.20,\n",
    "        \"6-10\": 0.15,\n",
    "        \"11-20\": 0.20,\n",
    "        \"20+\": 0.25,   # Long-term residents\n",
    "    },\n",
    "}\n",
    "\n",
    "# Validate distributions sum to 1.0\n",
    "for category, distribution in DEMOGRAPHICS.items():\n",
    "    total = sum(distribution.values())\n",
    "    assert abs(total - 1.0) < 0.01, f\"{category} sums to {total}, not 1.0\"\n",
    "    \n",
    "print(\"Demographics validated. Target distributions:\")\n",
    "for category, distribution in DEMOGRAPHICS.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for key, value in distribution.items():\n",
    "        print(f\"  {key}: {value:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataclasses-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Structures\n",
    "\n",
    "Define the core data classes for addresses, households, and people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dataclasses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structures defined. Target population: 100\n",
      "HouseholdMember now includes: industry, education (for SyntheticIdentity compatibility)\n"
     ]
    }
   ],
   "source": [
    "TARGET_POPULATION = 100  # Exact number of people to generate\n",
    "\n",
    "@dataclass\n",
    "class Address:\n",
    "    street: str\n",
    "    number: str\n",
    "    postcode: str = \"E8 2PB\"\n",
    "    property_type: str = \"Victorian terrace\"  # or \"converted_flat\", \"council_flat\", \"new_build\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.number} {self.street}, London {self.postcode}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HouseholdMember:\n",
    "    \"\"\"Member of a household - fields match SyntheticIdentity for easy conversion.\"\"\"\n",
    "    id: str\n",
    "    name: str\n",
    "    age: int\n",
    "    gender: str\n",
    "    relationship: str  # \"head\", \"spouse\", \"partner\", \"child\", \"parent\", \"flatmate\"\n",
    "    occupation: str\n",
    "    industry: str  # Industry sector for SyntheticIdentity\n",
    "    education: str  # Education level for SyntheticIdentity\n",
    "    ethnicity: str\n",
    "    political_lean: str\n",
    "    personality_sketch: str\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Household:\n",
    "    id: str\n",
    "    address: Address\n",
    "    household_type: str\n",
    "    tenure: str\n",
    "    years_in_area: int\n",
    "    socioeconomic: str\n",
    "    target_size: int = 1  # Pre-calculated to ensure total = TARGET_POPULATION\n",
    "    members: list[HouseholdMember] = field(default_factory=list)\n",
    "    \n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        return len(self.members)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Neighbourhood:\n",
    "    name: str\n",
    "    location: str\n",
    "    households: list[Household] = field(default_factory=list)\n",
    "    \n",
    "    @property\n",
    "    def total_residents(self) -> int:\n",
    "        return sum(h.size for h in self.households)\n",
    "    \n",
    "    def all_members(self) -> list[HouseholdMember]:\n",
    "        return [m for h in self.households for m in h.members]\n",
    "    \n",
    "    def get_member_by_id(self, member_id: str) -> Optional[HouseholdMember]:\n",
    "        for h in self.households:\n",
    "            for m in h.members:\n",
    "                if m.id == member_id:\n",
    "                    return m\n",
    "        return None\n",
    "\n",
    "print(f\"Data structures defined. Target population: {TARGET_POPULATION}\")\n",
    "print(f\"HouseholdMember now includes: industry, education (for SyntheticIdentity compatibility)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stage1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 1: Streets & Addresses\n",
    "\n",
    "Generate 42 addresses on fictional streets surrounding the plot. The streets should feel authentically Dalston - Victorian terraces mixed with post-war council blocks and some newer developments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stage1-streets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CACHED DATA FOUND - Loading existing neighbourhood\n",
      "============================================================\n",
      "\n",
      "  ../data/synthetic/dalston_clt/neighbourhood.json\n",
      "  ../data/synthetic/dalston_clt/personas.json\n",
      "\n",
      "  To regenerate, delete these files and rerun.\n",
      "\n",
      "✓ Skipping street generation (using cached data)\n"
     ]
    }
   ],
   "source": [
    "# CACHING: Check if neighbourhood data already exists\n",
    "NEIGHBOURHOOD_FILE = Path('../data/synthetic/dalston_clt/neighbourhood.json')\n",
    "PERSONAS_FILE = Path('../data/synthetic/dalston_clt/personas.json')\n",
    "\n",
    "if NEIGHBOURHOOD_FILE.exists() and PERSONAS_FILE.exists():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CACHED DATA FOUND - Loading existing neighbourhood\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\n  {NEIGHBOURHOOD_FILE}\")\n",
    "    print(f\"  {PERSONAS_FILE}\")\n",
    "    print(\"\\n  To regenerate, delete these files and rerun.\")\n",
    "    \n",
    "    SKIP_GENERATION = True\n",
    "else:\n",
    "    print(\"No cached data found. Will generate new neighbourhood.\")\n",
    "    SKIP_GENERATION = False\n",
    "\n",
    "if not SKIP_GENERATION:\n",
    "    # Generate new street names\n",
    "    STREETS_PROMPT = \"\"\"Generate 4 fictional street names for a neighbourhood in Dalston, East London (E8).\n",
    "\n",
    "    The streets should:\n",
    "    - Sound authentically London (mix of historical figures, local landmarks, trees, or trades)\n",
    "    - NOT be real Dalston street names\n",
    "    - Reflect the area's character (Victorian working-class origins, now gentrifying)\n",
    "\n",
    "    Return JSON array of 4 street names only, no \"Street\" or \"Road\" suffix:\n",
    "    [\"Name1\", \"Name2\", \"Name3\", \"Name4\"]\n",
    "\n",
    "    Return ONLY the JSON array.\"\"\"\n",
    "\n",
    "    result = await complete(STREETS_PROMPT)\n",
    "    text = result.content.strip()\n",
    "    if text.startswith(\"```\"): \n",
    "        text = text.split(\"```\")[1].replace(\"json\", \"\", 1).strip()\n",
    "    street_names = json.loads(text)\n",
    "\n",
    "    # Define street types and property mix\n",
    "    STREETS = [\n",
    "        {\"name\": f\"{street_names[0]} Road\", \"numbers\": range(1, 25, 2), \"property_type\": \"Victorian terrace\"},\n",
    "        {\"name\": f\"{street_names[1]} Street\", \"numbers\": range(2, 20, 2), \"property_type\": \"Victorian terrace\"},\n",
    "        {\"name\": f\"{street_names[2]} Estate\", \"numbers\": [f\"Flat {i}\" for i in range(1, 13)], \"property_type\": \"Council flat\"},\n",
    "        {\"name\": f\"{street_names[3]} Mews\", \"numbers\": range(1, 9), \"property_type\": \"New build\"},\n",
    "    ]\n",
    "\n",
    "    print(\"Generated streets:\")\n",
    "    for street in STREETS:\n",
    "        num_properties = len(list(street[\"numbers\"]))\n",
    "        print(f\"  {street['name']}: {num_properties} properties ({street['property_type']})\")\n",
    "else:\n",
    "    print(\"\\n✓ Skipping street generation (using cached data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stage1-addresses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Skipping address generation (using cached data)\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_GENERATION:\n",
    "    # Generate 42 addresses distributed across streets\n",
    "    addresses = []\n",
    "\n",
    "    for street in STREETS:\n",
    "        for number in street[\"numbers\"]:\n",
    "            addresses.append(Address(\n",
    "                street=street[\"name\"],\n",
    "                number=str(number),\n",
    "                property_type=street[\"property_type\"]\n",
    "            ))\n",
    "            if len(addresses) >= 42:\n",
    "                break\n",
    "        if len(addresses) >= 42:\n",
    "            break\n",
    "\n",
    "    print(f\"Generated {len(addresses)} addresses:\")\n",
    "    for addr in addresses[:5]:\n",
    "        print(f\"  {addr} ({addr.property_type})\")\n",
    "    print(f\"  ... and {len(addresses) - 5} more\")\n",
    "else:\n",
    "    print(\"✓ Skipping address generation (using cached data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stage2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 2: Household Allocation\n",
    "\n",
    "Assign household characteristics to each address based on target demographics. Property type influences likely tenure and household type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stage2-helpers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "def weighted_choice(distribution: dict) -> str:\n",
    "    \"\"\"Select from distribution based on weights.\"\"\"\n",
    "    items = list(distribution.keys())\n",
    "    weights = list(distribution.values())\n",
    "    return random.choices(items, weights=weights, k=1)[0]\n",
    "\n",
    "\n",
    "def years_from_bracket(bracket: str) -> int:\n",
    "    \"\"\"Convert bracket like '6-10' to a random year in that range.\"\"\"\n",
    "    if bracket == \"20+\":\n",
    "        return random.randint(20, 45)\n",
    "    parts = bracket.split(\"-\")\n",
    "    return random.randint(int(parts[0]), int(parts[1]))\n",
    "\n",
    "\n",
    "def get_expected_household_size(household_type: str) -> tuple[int, int]:\n",
    "    \"\"\"Return (min, max) household size for type.\"\"\"\n",
    "    sizes = {\n",
    "        \"single_person\": (1, 1),\n",
    "        \"couple_no_children\": (2, 2),\n",
    "        \"family_with_children\": (3, 5),\n",
    "        \"house_share\": (2, 4),\n",
    "        \"multi_generational\": (3, 6),\n",
    "    }\n",
    "    return sizes.get(household_type, (1, 4))\n",
    "\n",
    "\n",
    "# Property type influences tenure distribution\n",
    "TENURE_BY_PROPERTY = {\n",
    "    \"Victorian terrace\": {\"owner_occupied\": 0.45, \"private_rented\": 0.45, \"social_housing\": 0.10},\n",
    "    \"Council flat\": {\"owner_occupied\": 0.10, \"private_rented\": 0.15, \"social_housing\": 0.75},\n",
    "    \"New build\": {\"owner_occupied\": 0.50, \"private_rented\": 0.45, \"social_housing\": 0.05},\n",
    "}\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stage2-allocate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Skipping household allocation (using cached data)\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_GENERATION:\n",
    "    # Create households with allocated characteristics\n",
    "    households = []\n",
    "\n",
    "    for i, address in enumerate(addresses):\n",
    "        # Get tenure based on property type\n",
    "        tenure_dist = TENURE_BY_PROPERTY.get(address.property_type, DEMOGRAPHICS[\"tenure\"])\n",
    "        tenure = weighted_choice(tenure_dist)\n",
    "        \n",
    "        # Other characteristics from general demographics\n",
    "        household_type = weighted_choice(DEMOGRAPHICS[\"household_types\"])\n",
    "        socioeconomic = weighted_choice(DEMOGRAPHICS[\"socioeconomic\"])\n",
    "        years_bracket = weighted_choice(DEMOGRAPHICS[\"years_in_area\"])\n",
    "        years = years_from_bracket(years_bracket)\n",
    "        \n",
    "        # Initial size based on household type (will be adjusted to hit target)\n",
    "        min_size, max_size = get_expected_household_size(household_type)\n",
    "        initial_size = random.randint(min_size, max_size)\n",
    "        \n",
    "        household = Household(\n",
    "            id=f\"hh_{i+1:03d}\",\n",
    "            address=address,\n",
    "            household_type=household_type,\n",
    "            tenure=tenure,\n",
    "            years_in_area=years,\n",
    "            socioeconomic=socioeconomic,\n",
    "            target_size=initial_size,\n",
    "            members=[]\n",
    "        )\n",
    "        households.append(household)\n",
    "\n",
    "    # Adjust household sizes to sum to exactly TARGET_POPULATION\n",
    "    current_total = sum(h.target_size for h in households)\n",
    "    print(f\"Initial allocation: {current_total} people across {len(households)} households\")\n",
    "    print(f\"Adjusting by {TARGET_POPULATION - current_total:+d} to reach {TARGET_POPULATION}...\")\n",
    "\n",
    "    # Keep adjusting until we hit the target\n",
    "    max_iterations = 100\n",
    "    iteration = 0\n",
    "\n",
    "    while sum(h.target_size for h in households) != TARGET_POPULATION and iteration < max_iterations:\n",
    "        current_total = sum(h.target_size for h in households)\n",
    "        difference = TARGET_POPULATION - current_total\n",
    "        \n",
    "        if difference > 0:\n",
    "            adjustable = [h for h in households if h.target_size < get_expected_household_size(h.household_type)[1]]\n",
    "            if not adjustable:\n",
    "                adjustable = [h for h in households if h.household_type != \"single_person\"]\n",
    "            if not adjustable:\n",
    "                adjustable = list(households)\n",
    "            random.shuffle(adjustable)\n",
    "            adjustable[0].target_size += 1\n",
    "            \n",
    "        elif difference < 0:\n",
    "            adjustable = [h for h in households if h.target_size > get_expected_household_size(h.household_type)[0]]\n",
    "            if not adjustable:\n",
    "                adjustable = [h for h in households if h.target_size > 1]\n",
    "            if adjustable:\n",
    "                random.shuffle(adjustable)\n",
    "                adjustable[0].target_size -= 1\n",
    "        \n",
    "        iteration += 1\n",
    "\n",
    "    final_total = sum(h.target_size for h in households)\n",
    "    assert final_total == TARGET_POPULATION, f\"Failed to reach target after {max_iterations} iterations: got {final_total}\"\n",
    "\n",
    "    print(f\"Final allocation: {final_total} people across {len(households)} households\")\n",
    "    print(f\"Average household size: {final_total / len(households):.2f}\\n\")\n",
    "\n",
    "    # Show distribution summary\n",
    "    from collections import Counter\n",
    "\n",
    "    print(\"Household type distribution:\")\n",
    "    type_counts = Counter(h.household_type for h in households)\n",
    "    for htype, count in sorted(type_counts.items()):\n",
    "        print(f\"  {htype}: {count} ({count/len(households):.0%})\")\n",
    "\n",
    "    print(\"\\nTenure distribution:\")\n",
    "    tenure_counts = Counter(h.tenure for h in households)\n",
    "    for tenure, count in sorted(tenure_counts.items()):\n",
    "        print(f\"  {tenure}: {count} ({count/len(households):.0%})\")\n",
    "\n",
    "    print(\"\\nHousehold size distribution:\")\n",
    "    size_counts = Counter(h.target_size for h in households)\n",
    "    for size, count in sorted(size_counts.items()):\n",
    "        print(f\"  {size} person(s): {count} households\")\n",
    "else:\n",
    "    print(\"✓ Skipping household allocation (using cached data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stage3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 3: Generate People\n",
    "\n",
    "For each household, generate members using the LLM. Pass context about the household and a running list of already-generated names to prevent duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stage3-prompt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt builder defined (now includes industry and education fields).\n"
     ]
    }
   ],
   "source": [
    "def build_household_generation_prompt(household: Household, existing_names: list[str]) -> str:\n",
    "    \"\"\"Build prompt for generating household members. Uses household.target_size.\"\"\"\n",
    "    \n",
    "    target_size = household.target_size\n",
    "    \n",
    "    # Build household context - adjust description based on actual target size\n",
    "    if household.household_type == \"single_person\":\n",
    "        household_desc = \"a single adult living alone\"\n",
    "    elif household.household_type == \"couple_no_children\":\n",
    "        household_desc = \"a couple without children\"\n",
    "    elif household.household_type == \"family_with_children\":\n",
    "        num_children = max(1, target_size - 2)\n",
    "        household_desc = f\"a family with {num_children} child(ren)\"\n",
    "    elif household.household_type == \"house_share\":\n",
    "        household_desc = f\"{target_size} unrelated adults sharing the property\"\n",
    "    elif household.household_type == \"multi_generational\":\n",
    "        household_desc = \"multiple generations living together (e.g., grandparent, parent, child)\"\n",
    "    else:\n",
    "        household_desc = f\"{target_size} people\"\n",
    "    \n",
    "    tenure_desc = {\n",
    "        \"owner_occupied\": \"owns the property\",\n",
    "        \"private_rented\": \"rents privately\",\n",
    "        \"social_housing\": \"lives in social/council housing\",\n",
    "    }\n",
    "    \n",
    "    socio_desc = {\n",
    "        \"working_class\": \"working-class background (manual labour, service jobs, trades)\",\n",
    "        \"lower_middle\": \"lower-middle class (clerical, small business, skilled trades)\",\n",
    "        \"middle_class\": \"middle class (teachers, nurses, mid-level professionals)\",\n",
    "        \"professional\": \"professional class (lawyers, doctors, tech workers, executives)\",\n",
    "    }\n",
    "    \n",
    "    existing_names_str = \", \".join(existing_names[-50:]) if existing_names else \"None yet\"\n",
    "    \n",
    "    prompt = f\"\"\"Generate EXACTLY {target_size} person(s) for a household in Dalston, East London (E8).\n",
    "\n",
    "HOUSEHOLD CONTEXT:\n",
    "- Address: {household.address}\n",
    "- Type: {household_desc}\n",
    "- Tenure: {tenure_desc[household.tenure]}\n",
    "- Socioeconomic: {socio_desc[household.socioeconomic]}\n",
    "- Years in area: {household.years_in_area}\n",
    "- Property: {household.address.property_type}\n",
    "\n",
    "DALSTON DEMOGRAPHICS:\n",
    "- Highly diverse: White British 30%, Black British 22%, Turkish/Kurdish 12%, South Asian 8%, White European 15%, Mixed 8%, East Asian 5%\n",
    "- This household's ethnicity should be consistent (family members share ethnicity, flatmates may differ)\n",
    "- Names should reflect ethnicity realistically\n",
    "- Include young adults (18-24) and older people (65+), not just 25-45 year olds\n",
    "\n",
    "AVOID THESE NAMES (already used): {existing_names_str}\n",
    "\n",
    "For each person, provide:\n",
    "- name: Full name (realistic for their ethnicity)\n",
    "- age: Integer (realistic spread including 18-24 and 65+, not just 25-45)\n",
    "- gender: \"male\", \"female\", or \"non-binary\"\n",
    "- relationship: Role in household (\"head\", \"spouse\", \"partner\", \"child\", \"parent\", \"flatmate\")\n",
    "- occupation: Current job or status (student, retired, unemployed, etc.)\n",
    "- industry: Industry sector (e.g., \"Healthcare\", \"Education\", \"Retail\", \"Trades\", \"Hospitality\", \"Technology\", \"Transport\", \"Finance\", \"Creative\", \"Public sector\", \"Retired\", \"Student\", \"Unemployed\")\n",
    "- education: Highest education level (e.g., \"Secondary school\", \"GCSEs\", \"A-levels\", \"Vocational/trade certificate\", \"Some college\", \"Bachelor's degree\", \"Master's degree\", \"PhD\", \"No formal qualifications\")\n",
    "- ethnicity: Specific ethnicity\n",
    "- political_lean: Political orientation (be realistic - include conservatives, apolitical people, not just progressives)\n",
    "- personality_sketch: 2-3 sentences about personality, interests, daily life\n",
    "\n",
    "Return ONLY a JSON array with EXACTLY {target_size} person object(s). No explanation.\"\"\"\n",
    "    \n",
    "    return prompt, target_size\n",
    "\n",
    "print(\"Prompt builder defined (now includes industry and education fields).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jd7dpyonj9s",
   "metadata": {},
   "source": [
    "### Cost Estimation\n",
    "\n",
    "Before running 42 LLM calls, estimate the total cost based on prompt sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wehwgnswyca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Skipping cost estimation (using cached data)\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_GENERATION:\n",
    "    # Estimate total cost before running\n",
    "    print(\"COST ESTIMATION\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Build sample prompts to estimate token counts\n",
    "    sample_estimates = []\n",
    "    simulated_names = []\n",
    "\n",
    "    for household in households:\n",
    "        prompt, expected_size = build_household_generation_prompt(household, simulated_names)\n",
    "        \n",
    "        # Estimate ~150 tokens per person in response (name, age, occupation, personality sketch, etc.)\n",
    "        estimated_output_tokens = expected_size * 150\n",
    "        \n",
    "        estimate = estimate_cost(\n",
    "            prompt=prompt,\n",
    "            estimated_completion_tokens=estimated_output_tokens,\n",
    "        )\n",
    "        sample_estimates.append(estimate)\n",
    "        \n",
    "        # Simulate name accumulation for accurate prompt length estimation\n",
    "        simulated_names.extend([f\"Person {i}\" for i in range(expected_size)])\n",
    "\n",
    "    total_prompt_tokens = sum(e.prompt_tokens for e in sample_estimates)\n",
    "    total_completion_tokens = sum(e.completion_tokens for e in sample_estimates)\n",
    "    total_cost = sum(e.cost for e in sample_estimates)\n",
    "\n",
    "    print(f\"\\nTarget: {TARGET_POPULATION} people across {len(households)} households\")\n",
    "    print(f\"\\nEstimated tokens:\")\n",
    "    print(f\"  Prompt tokens:     {total_prompt_tokens:,}\")\n",
    "    print(f\"  Completion tokens: {total_completion_tokens:,} (estimated)\")\n",
    "    print(f\"  Total tokens:      {total_prompt_tokens + total_completion_tokens:,}\")\n",
    "    print(f\"\\n  Estimated cost: ${total_cost:.4f}\")\n",
    "\n",
    "    # Show cost breakdown\n",
    "    print(f\"\\nPer-unit estimates:\")\n",
    "    print(f\"  Per household: ${total_cost / len(households):.4f}\")\n",
    "    print(f\"  Per person:    ${total_cost / TARGET_POPULATION:.4f}\")\n",
    "else:\n",
    "    print(\"✓ Skipping cost estimation (using cached data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tez3grty3pq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confirm before proceeding (comment out to skip)\n",
    "# proceed = input(f\"Proceed with generation? Estimated cost: ${total_cost:.4f} (y/n): \")\n",
    "# if proceed.lower() != 'y':\n",
    "#     raise KeyboardInterrupt(\"Generation cancelled by user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stage3-generate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Skipping member generation (using cached data)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "if not SKIP_GENERATION:\n",
    "    async def generate_household_members(household: Household, existing_names: list[str]) -> tuple[Household, list[dict], float]:\n",
    "        \"\"\"Generate members for a single household. Returns (household, members_data, cost).\"\"\"\n",
    "        prompt, expected_size = build_household_generation_prompt(household, existing_names)\n",
    "        \n",
    "        result = await complete(prompt)\n",
    "        \n",
    "        text = result.content.strip()\n",
    "        if text.startswith(\"```\"): \n",
    "            text = text.split(\"```\")[1].replace(\"json\", \"\", 1).strip()\n",
    "        \n",
    "        try:\n",
    "            members_data = json.loads(text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"  ERROR parsing household {household.id}: {e}\")\n",
    "            members_data = []\n",
    "        \n",
    "        return household, members_data, result.cost, expected_size\n",
    "\n",
    "\n",
    "    # Generate members for all households in parallel batches\n",
    "    all_names = []\n",
    "    total_generated = 0\n",
    "    total_cost_actual = 0.0\n",
    "    size_mismatches = []\n",
    "\n",
    "    # Batch size - balance between parallelism and name deduplication\n",
    "    BATCH_SIZE = 10\n",
    "\n",
    "    print(f\"Generating household members in batches of {BATCH_SIZE}...\\n\")\n",
    "\n",
    "    for batch_start in tqdm(range(0, len(households), BATCH_SIZE), desc=\"Batches\", unit=\"batch\"):\n",
    "        batch = households[batch_start:batch_start + BATCH_SIZE]\n",
    "        \n",
    "        # Run batch in parallel\n",
    "        tasks = [generate_household_members(h, all_names.copy()) for h in batch]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # Process results\n",
    "        for household, members_data, cost, expected_size in results:\n",
    "            total_cost_actual += cost\n",
    "            \n",
    "            if len(members_data) != expected_size:\n",
    "                size_mismatches.append((household.id, expected_size, len(members_data)))\n",
    "            \n",
    "            for j, m in enumerate(members_data):\n",
    "                member = HouseholdMember(\n",
    "                    id=f\"{household.id}_p{j+1}\",\n",
    "                    name=m[\"name\"],\n",
    "                    age=m[\"age\"],\n",
    "                    gender=m[\"gender\"],\n",
    "                    relationship=m[\"relationship\"],\n",
    "                    occupation=m[\"occupation\"],\n",
    "                    industry=m.get(\"industry\", \"Other\"),  # New field\n",
    "                    education=m.get(\"education\", \"Secondary school\"),  # New field\n",
    "                    ethnicity=m[\"ethnicity\"],\n",
    "                    political_lean=m[\"political_lean\"],\n",
    "                    personality_sketch=m[\"personality_sketch\"],\n",
    "                )\n",
    "                household.members.append(member)\n",
    "                all_names.append(m[\"name\"])\n",
    "            \n",
    "            total_generated += len(members_data)\n",
    "\n",
    "    print(f\"\\nComplete!\")\n",
    "    print(f\"  Generated {total_generated} people across {len(households)} households\")\n",
    "    print(f\"  Target was {TARGET_POPULATION} people\")\n",
    "    print(f\"  Actual cost: ${total_cost_actual:.4f}\")\n",
    "\n",
    "    if size_mismatches:\n",
    "        print(f\"\\n  WARNING: {len(size_mismatches)} households had size mismatches:\")\n",
    "        for hh_id, expected, actual in size_mismatches[:5]:\n",
    "            print(f\"    {hh_id}: expected {expected}, got {actual}\")\n",
    "        if len(size_mismatches) > 5:\n",
    "            print(f\"    ... and {len(size_mismatches) - 5} more\")\n",
    "\n",
    "    if total_generated != TARGET_POPULATION:\n",
    "        print(f\"\\n  ⚠️  POPULATION MISMATCH: Got {total_generated}, expected {TARGET_POPULATION}\")\n",
    "    else:\n",
    "        print(f\"\\n  ✓ Successfully generated exactly {TARGET_POPULATION} people\")\n",
    "else:\n",
    "    print(\"✓ Skipping member generation (using cached data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stage3-preview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Skipping preview (will show after loading cache in Stage 4)\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_GENERATION:\n",
    "    # Preview some households (only after fresh generation)\n",
    "    print(\"Sample households:\\n\")\n",
    "\n",
    "    for household in households[:5]:\n",
    "        print(f\"{household.address}\")\n",
    "        print(f\"  Type: {household.household_type} | Tenure: {household.tenure} | Years: {household.years_in_area}\")\n",
    "        for m in household.members:\n",
    "            print(f\"  - {m.name}, {m.age}, {m.gender} ({m.relationship})\")\n",
    "            print(f\"    {m.occupation} | {m.industry} | {m.education}\")\n",
    "            print(f\"    {m.ethnicity} | {m.political_lean}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"✓ Skipping preview (will show after loading cache in Stage 4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stage4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 4: Validation\n",
    "\n",
    "Check the generated neighbourhood for issues:\n",
    "- Duplicate names\n",
    "- Demographic distribution matches targets\n",
    "- Household compositions are coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stage4-validate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading neighbourhood from cache...\n",
      "  Loaded 41 households from cache\n",
      "\n",
      "NEIGHBOURHOOD SUMMARY\n",
      "==================================================\n",
      "Total households: 41\n",
      "Total residents: 100\n",
      "Target population: 100\n",
      "Average household size: 2.4\n",
      "\n",
      "✓ Population target met: exactly 100 people\n",
      "\n",
      "DUPLICATE NAMES: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "if SKIP_GENERATION:\n",
    "    # Load from cached files\n",
    "    print(\"Loading neighbourhood from cache...\")\n",
    "    \n",
    "    with open(NEIGHBOURHOOD_FILE) as f:\n",
    "        cached_data = json.load(f)\n",
    "    \n",
    "    # Reconstruct households and members from cached data\n",
    "    households = []\n",
    "    for hh_data in cached_data[\"households\"]:\n",
    "        addr_data = hh_data[\"address\"]\n",
    "        address = Address(\n",
    "            street=addr_data[\"street\"],\n",
    "            number=addr_data[\"number\"],\n",
    "            postcode=addr_data[\"postcode\"],\n",
    "            property_type=addr_data[\"property_type\"],\n",
    "        )\n",
    "        \n",
    "        household = Household(\n",
    "            id=hh_data[\"id\"],\n",
    "            address=address,\n",
    "            household_type=hh_data[\"household_type\"],\n",
    "            tenure=hh_data[\"tenure\"],\n",
    "            years_in_area=hh_data[\"years_in_area\"],\n",
    "            socioeconomic=hh_data[\"socioeconomic\"],\n",
    "            members=[]\n",
    "        )\n",
    "        \n",
    "        for m_data in hh_data[\"members\"]:\n",
    "            member = HouseholdMember(\n",
    "                id=m_data[\"id\"],\n",
    "                name=m_data[\"name\"],\n",
    "                age=m_data[\"age\"],\n",
    "                gender=m_data[\"gender\"],\n",
    "                relationship=m_data[\"relationship\"],\n",
    "                occupation=m_data[\"occupation\"],\n",
    "                industry=m_data.get(\"industry\", \"Other\"),  # Handle old data\n",
    "                education=m_data.get(\"education\", \"Secondary school\"),  # Handle old data\n",
    "                ethnicity=m_data[\"ethnicity\"],\n",
    "                political_lean=m_data[\"political_lean\"],\n",
    "                personality_sketch=m_data[\"personality_sketch\"],\n",
    "            )\n",
    "            household.members.append(member)\n",
    "        \n",
    "        households.append(household)\n",
    "    \n",
    "    print(f\"  Loaded {len(households)} households from cache\")\n",
    "\n",
    "# Create neighbourhood object (works for both cached and newly generated)\n",
    "neighbourhood = Neighbourhood(\n",
    "    name=\"Dalston CLT\",\n",
    "    location=\"Dalston, London E8\",\n",
    "    households=households\n",
    ")\n",
    "\n",
    "all_members = neighbourhood.all_members()\n",
    "\n",
    "print(f\"\\nNEIGHBOURHOOD SUMMARY\")\n",
    "print(f\"=\"*50)\n",
    "print(f\"Total households: {len(neighbourhood.households)}\")\n",
    "print(f\"Total residents: {neighbourhood.total_residents}\")\n",
    "print(f\"Target population: {TARGET_POPULATION}\")\n",
    "print(f\"Average household size: {neighbourhood.total_residents / len(neighbourhood.households):.1f}\")\n",
    "\n",
    "# Validate population\n",
    "if neighbourhood.total_residents == TARGET_POPULATION:\n",
    "    print(f\"\\n✓ Population target met: exactly {TARGET_POPULATION} people\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  Population mismatch: {neighbourhood.total_residents} vs target {TARGET_POPULATION}\")\n",
    "\n",
    "# Check for duplicate names\n",
    "name_counts = Counter(m.name for m in all_members)\n",
    "duplicates = {name: count for name, count in name_counts.items() if count > 1}\n",
    "\n",
    "print(f\"\\nDUPLICATE NAMES: {len(duplicates)}\")\n",
    "if duplicates:\n",
    "    for name, count in duplicates.items():\n",
    "        print(f\"  {name}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stage4-demographics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMOGRAPHIC ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Total: 100 people (94 adults, 6 children)\n",
      "\n",
      "Age distribution (adults only):\n",
      "  18-24: 25 (26.6%) [target: 12%] ⚠️\n",
      "  25-34: 16 (17.0%) [target: 28%] ⚠️\n",
      "  35-44: 17 (18.1%) [target: 22%] ✓\n",
      "  45-54: 10 (10.6%) [target: 15%] ✓\n",
      "  55-64: 3 (3.2%) [target: 12%] ~\n",
      "  65+: 23 (24.5%) [target: 11%] ⚠️\n",
      "\n",
      "Gender distribution:\n",
      "  female: 56 (56.0%)\n",
      "  male: 43 (43.0%)\n",
      "  non-binary: 1 (1.0%)\n",
      "\n",
      "Ethnicity distribution:\n",
      "  black british: 14 (14.0%) [target: 0%] ⚠️\n",
      "  east_asian: 3 (3.0%) [target: 5%] ✓\n",
      "  greek: 1 (1.0%) [target: 0%] ✓\n",
      "  south_asian: 9 (9.0%) [target: 8%] ✓\n",
      "  turkish_kurdish: 32 (32.0%) [target: 12%] ⚠️\n",
      "  white_british: 25 (25.0%) [target: 30%] ~\n",
      "  white_other: 16 (16.0%) [target: 15%] ✓\n",
      "\n",
      "Political lean:\n",
      "  progressive: 21 (21.0%)\n",
      "  liberal: 17 (17.0%)\n",
      "  apolitical: 15 (15.0%)\n",
      "  centrist: 10 (10.0%)\n",
      "  moderate: 9 (9.0%)\n",
      "  conservative: 8 (8.0%)\n",
      "  labour: 4 (4.0%)\n",
      "  centre-left: 3 (3.0%)\n",
      "  neutral: 1 (1.0%)\n",
      "  left-leaning: 1 (1.0%)\n",
      "  traditional labour: 1 (1.0%)\n",
      "  moderate liberal: 1 (1.0%)\n",
      "  green: 1 (1.0%)\n",
      "  liberal democrat: 1 (1.0%)\n",
      "  labour supporter: 1 (1.0%)\n",
      "  slightly conservative: 1 (1.0%)\n",
      "  center-left: 1 (1.0%)\n",
      "  green party: 1 (1.0%)\n",
      "  too young for political preference: 1 (1.0%)\n",
      "  none: 1 (1.0%)\n",
      "  green party supporter: 1 (1.0%)\n",
      "\n",
      "Occupation diversity: 40 unique occupations\n",
      "Top 10:\n",
      "  retired: 18\n",
      "  student: 15\n",
      "  nurse: 7\n",
      "  barista: 5\n",
      "  electrician: 4\n",
      "  university student: 4\n",
      "  shop assistant: 3\n",
      "  secondary school teacher: 3\n",
      "  lawyer: 3\n",
      "  mechanic: 3\n",
      "\n",
      "==================================================\n",
      "HOUSEHOLD-LEVEL ANALYSIS\n",
      "\n",
      "Socioeconomic by tenure:\n",
      "  owner_occupied:\n",
      "    lower_middle: 6\n",
      "    middle_class: 4\n",
      "    professional: 2\n",
      "    working_class: 2\n",
      "  private_rented:\n",
      "    lower_middle: 5\n",
      "    middle_class: 3\n",
      "    professional: 1\n",
      "    working_class: 6\n",
      "  social_housing:\n",
      "    lower_middle: 3\n",
      "    middle_class: 5\n",
      "    professional: 2\n",
      "    working_class: 2\n",
      "\n",
      "Years in area (households):\n",
      "  0-2: 11 (26.8%) [target: 20%] ~\n",
      "  11-20: 5 (12.2%) [target: 20%] ~\n",
      "  20+: 11 (26.8%) [target: 25%] ✓\n",
      "  3-5: 7 (17.1%) [target: 20%] ✓\n",
      "  6-10: 7 (17.1%) [target: 15%] ✓\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive demographic analysis\n",
    "print(\"DEMOGRAPHIC ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Helper to compare actual vs target\n",
    "def compare_distribution(name: str, actual: dict, target: dict = None):\n",
    "    print(f\"\\n{name}:\")\n",
    "    total = sum(actual.values())\n",
    "    for key in sorted(actual.keys()):\n",
    "        count = actual[key]\n",
    "        pct = count / total * 100 if total > 0 else 0\n",
    "        target_pct = target.get(key, 0) * 100 if target else None\n",
    "        if target_pct is not None:\n",
    "            diff = pct - target_pct\n",
    "            flag = \"⚠️\" if abs(diff) > 10 else \"✓\" if abs(diff) < 5 else \"~\"\n",
    "            print(f\"  {key}: {count} ({pct:.1f}%) [target: {target_pct:.0f}%] {flag}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# Age distribution (excluding children from target comparison)\n",
    "adults = [m for m in all_members if m.age >= 18]\n",
    "children = [m for m in all_members if m.age < 18]\n",
    "print(f\"\\nTotal: {len(all_members)} people ({len(adults)} adults, {len(children)} children)\")\n",
    "\n",
    "age_brackets = {\"18-24\": 0, \"25-34\": 0, \"35-44\": 0, \"45-54\": 0, \"55-64\": 0, \"65+\": 0}\n",
    "for m in adults:\n",
    "    if m.age <= 24: age_brackets[\"18-24\"] += 1\n",
    "    elif m.age <= 34: age_brackets[\"25-34\"] += 1\n",
    "    elif m.age <= 44: age_brackets[\"35-44\"] += 1\n",
    "    elif m.age <= 54: age_brackets[\"45-54\"] += 1\n",
    "    elif m.age <= 64: age_brackets[\"55-64\"] += 1\n",
    "    else: age_brackets[\"65+\"] += 1\n",
    "\n",
    "compare_distribution(\"Age distribution (adults only)\", age_brackets, DEMOGRAPHICS[\"age_brackets\"])\n",
    "\n",
    "# Gender distribution\n",
    "gender_counts = Counter(m.gender.lower() for m in all_members)\n",
    "compare_distribution(\"Gender distribution\", dict(gender_counts))\n",
    "\n",
    "# Ethnicity distribution\n",
    "ethnicity_counts = Counter(m.ethnicity.lower() for m in all_members)\n",
    "# Normalize ethnicity labels for comparison\n",
    "ethnicity_normalized = {}\n",
    "for eth, count in ethnicity_counts.items():\n",
    "    # Try to map to our categories\n",
    "    if \"white\" in eth and \"british\" in eth:\n",
    "        key = \"white_british\"\n",
    "    elif \"white\" in eth or \"european\" in eth or \"irish\" in eth or \"polish\" in eth or \"italian\" in eth:\n",
    "        key = \"white_other\"\n",
    "    elif \"caribbean\" in eth:\n",
    "        key = \"black_british_caribbean\"\n",
    "    elif \"african\" in eth or \"nigerian\" in eth or \"ghanaian\" in eth:\n",
    "        key = \"black_british_african\"\n",
    "    elif \"turkish\" in eth or \"kurdish\" in eth:\n",
    "        key = \"turkish_kurdish\"\n",
    "    elif \"indian\" in eth or \"pakistani\" in eth or \"bangladeshi\" in eth or \"south asian\" in eth:\n",
    "        key = \"south_asian\"\n",
    "    elif \"chinese\" in eth or \"japanese\" in eth or \"korean\" in eth or \"east asian\" in eth or \"vietnamese\" in eth:\n",
    "        key = \"east_asian\"\n",
    "    elif \"mixed\" in eth:\n",
    "        key = \"mixed\"\n",
    "    else:\n",
    "        key = eth  # Keep original if no match\n",
    "    ethnicity_normalized[key] = ethnicity_normalized.get(key, 0) + count\n",
    "\n",
    "compare_distribution(\"Ethnicity distribution\", ethnicity_normalized, DEMOGRAPHICS[\"ethnicity\"])\n",
    "\n",
    "# Political lean\n",
    "political_counts = Counter(m.political_lean.lower() for m in all_members)\n",
    "print(f\"\\nPolitical lean:\")\n",
    "for lean, count in sorted(political_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {lean}: {count} ({count/len(all_members)*100:.1f}%)\")\n",
    "\n",
    "# Occupation diversity\n",
    "occupation_counts = Counter(m.occupation.lower() for m in all_members)\n",
    "print(f\"\\nOccupation diversity: {len(occupation_counts)} unique occupations\")\n",
    "print(\"Top 10:\")\n",
    "for occ, count in occupation_counts.most_common(10):\n",
    "    print(f\"  {occ}: {count}\")\n",
    "\n",
    "# Household-level stats\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(\"HOUSEHOLD-LEVEL ANALYSIS\")\n",
    "\n",
    "# Socioeconomic by tenure\n",
    "print(\"\\nSocioeconomic by tenure:\")\n",
    "for tenure in [\"owner_occupied\", \"private_rented\", \"social_housing\"]:\n",
    "    hh_with_tenure = [h for h in households if h.tenure == tenure]\n",
    "    if hh_with_tenure:\n",
    "        socio_counts = Counter(h.socioeconomic for h in hh_with_tenure)\n",
    "        print(f\"  {tenure}:\")\n",
    "        for socio, count in sorted(socio_counts.items()):\n",
    "            print(f\"    {socio}: {count}\")\n",
    "\n",
    "# Years in area distribution\n",
    "years_brackets = {\"0-2\": 0, \"3-5\": 0, \"6-10\": 0, \"11-20\": 0, \"20+\": 0}\n",
    "for h in households:\n",
    "    if h.years_in_area <= 2: years_brackets[\"0-2\"] += 1\n",
    "    elif h.years_in_area <= 5: years_brackets[\"3-5\"] += 1\n",
    "    elif h.years_in_area <= 10: years_brackets[\"6-10\"] += 1\n",
    "    elif h.years_in_area <= 20: years_brackets[\"11-20\"] += 1\n",
    "    else: years_brackets[\"20+\"] += 1\n",
    "\n",
    "compare_distribution(\"Years in area (households)\", years_brackets, DEMOGRAPHICS[\"years_in_area\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stage5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 5: Export\n",
    "\n",
    "Save the neighbourhood data for use in the Testing space before it happens experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "stage5-export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Skipping export (using cached neighbourhood.json)\n"
     ]
    }
   ],
   "source": [
    "# Export to JSON (only if newly generated)\n",
    "output_dir = Path('../data/synthetic/dalston_clt')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not SKIP_GENERATION:\n",
    "    # Convert to serializable format\n",
    "    def household_to_dict(h: Household) -> dict:\n",
    "        return {\n",
    "            \"id\": h.id,\n",
    "            \"address\": {\n",
    "                \"street\": h.address.street,\n",
    "                \"number\": h.address.number,\n",
    "                \"postcode\": h.address.postcode,\n",
    "                \"property_type\": h.address.property_type,\n",
    "            },\n",
    "            \"household_type\": h.household_type,\n",
    "            \"tenure\": h.tenure,\n",
    "            \"years_in_area\": h.years_in_area,\n",
    "            \"socioeconomic\": h.socioeconomic,\n",
    "            \"members\": [asdict(m) for m in h.members]\n",
    "        }\n",
    "\n",
    "    neighbourhood_data = {\n",
    "        \"name\": neighbourhood.name,\n",
    "        \"location\": neighbourhood.location,\n",
    "        \"generated_at\": str(Path.cwd()),\n",
    "        \"total_households\": len(neighbourhood.households),\n",
    "        \"total_residents\": neighbourhood.total_residents,\n",
    "        \"households\": [household_to_dict(h) for h in neighbourhood.households]\n",
    "    }\n",
    "\n",
    "    output_file = output_dir / 'neighbourhood.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(neighbourhood_data, f, indent=2)\n",
    "\n",
    "    print(f\"Exported neighbourhood to {output_file}\")\n",
    "    print(f\"  {neighbourhood_data['total_households']} households\")\n",
    "    print(f\"  {neighbourhood_data['total_residents']} residents\")\n",
    "else:\n",
    "    print(f\"✓ Skipping export (using cached {NEIGHBOURHOOD_FILE.name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stage5-personas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Skipping personas export (using cached personas.json)\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_GENERATION:\n",
    "    # Export a flat list of personas for easy surveying\n",
    "    # Now includes industry and education for direct SyntheticIdentity conversion\n",
    "    personas_list = []\n",
    "\n",
    "    for household in neighbourhood.households:\n",
    "        for member in household.members:\n",
    "            persona_data = {\n",
    "                \"id\": member.id,\n",
    "                \"name\": member.name,\n",
    "                \"age\": member.age,\n",
    "                \"gender\": member.gender,\n",
    "                \"occupation\": member.occupation,\n",
    "                \"industry\": member.industry,  # New field\n",
    "                \"education\": member.education,  # New field\n",
    "                \"ethnicity\": member.ethnicity,\n",
    "                \"political_lean\": member.political_lean,\n",
    "                \"personality_sketch\": member.personality_sketch,\n",
    "                \"household_id\": household.id,\n",
    "                \"address\": str(household.address),\n",
    "                \"tenure\": household.tenure,\n",
    "                \"years_in_area\": household.years_in_area,\n",
    "                \"socioeconomic\": household.socioeconomic,\n",
    "            }\n",
    "            personas_list.append(persona_data)\n",
    "\n",
    "    personas_file = output_dir / 'personas.json'\n",
    "    with open(personas_file, 'w') as f:\n",
    "        json.dump(personas_list, f, indent=2)\n",
    "\n",
    "    print(f\"Exported {len(personas_list)} personas to {personas_file}\")\n",
    "    print(f\"  (includes industry and education for SyntheticIdentity compatibility)\")\n",
    "else:\n",
    "    print(f\"✓ Skipping personas export (using cached {PERSONAS_FILE.name})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 6: Generate Data Files\n",
    "\n",
    "Generate synthetic personal data files (CV, reading list, subscriptions) for each persona. These files will then be processed to create rich context statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "oxclslc32yl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 personas\n",
      "\n",
      "Available file types: ['cv', 'linkedin_summary', 'work_calendar', 'email_signature', 'twitter_bio', 'instagram_bio', 'facebook_about', 'reddit_profile', 'tiktok_profile', 'nextdoor_activity', 'reading_list', 'subscriptions', 'spotify_favorites', 'netflix_history', 'youtube_subscriptions', 'podcast_subscriptions', 'amazon_wishlist', 'shopping_history', 'grocery_list', 'loyalty_programs', 'google_reviews', 'product_reviews', 'yelp_reviews', 'notes_snippet', 'bookmarks', 'text_messages', 'voicemail_greeting', 'fitness_tracker', 'health_goals', 'travel_history', 'location_history', 'bank_categories', 'charity_donations', 'home_description', 'pet_profile', 'vehicle_info', 'recipe_collection', 'dating_profile', 'forum_posts', 'event_attendance']\n",
      "\n",
      "============================================================\n",
      "COST ESTIMATION: File Generation + Context Extraction\n",
      "============================================================\n",
      "\n",
      "Configuration:\n",
      "  Model: gpt-4o\n",
      "  Personas: 100\n",
      "  Files per persona: 2-5 (inferred based on occupation/age)\n",
      "\n",
      "Per-persona estimates (avg 3.5 files):\n",
      "  Prompt tokens: 4,525\n",
      "  Completion tokens: 1,575\n",
      "  Total tokens: 6,100\n",
      "\n",
      "Total estimates (100 personas):\n",
      "  Prompt tokens: 452,500\n",
      "  Completion tokens: 157,500\n",
      "  Total tokens: 610,000\n",
      "\n",
      "  Estimated cost: $2.71 (GPT-4o pricing)\n",
      "  With 20% safety margin: $3.25\n"
     ]
    }
   ],
   "source": [
    "# Cost estimation for file generation\n",
    "# \n",
    "# For each persona, we generate 2-5 files based on their characteristics\n",
    "# (not everyone has a CV - retirees, students, etc.)\n",
    "# Then process them to extract a context statement\n",
    "\n",
    "from centuria.persona import (\n",
    "    SyntheticIdentity, \n",
    "    generate_synthetic_files, \n",
    "    list_available_file_types,\n",
    "    infer_file_types_for_identity,\n",
    ")\n",
    "import os\n",
    "\n",
    "# Load our personas\n",
    "with open('../data/synthetic/dalston_clt/personas.json') as f:\n",
    "    personas_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(personas_data)} personas\")\n",
    "print(f\"\\nAvailable file types: {list(list_available_file_types().keys())}\")\n",
    "\n",
    "# Estimate costs\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COST ESTIMATION: File Generation + Context Extraction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Per-file estimates (based on prompts in synthetic.py)\n",
    "FILE_PROMPT_TOKENS = 350  # Average prompt size for file generation\n",
    "FILE_COMPLETION_TOKENS = 250  # Average response size\n",
    "\n",
    "# Extraction estimates (based on extractors.py)\n",
    "EXTRACTION_PROMPT_TOKENS = 1800  # Profile extraction from files\n",
    "EXTRACTION_COMPLETION_TOKENS = 200\n",
    "\n",
    "# Context statement estimates  \n",
    "CONTEXT_PROMPT_TOKENS = 1500  # Building context from profile + raw data\n",
    "CONTEXT_COMPLETION_TOKENS = 500  # 300-500 word statement\n",
    "\n",
    "# Average files per persona (using infer_file_types_for_identity)\n",
    "AVG_FILES_PER_PERSONA = 3.5  # Range is 2-5, weighted average ~3.5\n",
    "\n",
    "# Calculate per-persona totals\n",
    "prompt_per_persona = (\n",
    "    (FILE_PROMPT_TOKENS * AVG_FILES_PER_PERSONA) +\n",
    "    EXTRACTION_PROMPT_TOKENS + \n",
    "    CONTEXT_PROMPT_TOKENS\n",
    ")\n",
    "completion_per_persona = (\n",
    "    (FILE_COMPLETION_TOKENS * AVG_FILES_PER_PERSONA) +\n",
    "    EXTRACTION_COMPLETION_TOKENS +\n",
    "    CONTEXT_COMPLETION_TOKENS\n",
    ")\n",
    "\n",
    "# Total for all personas\n",
    "num_personas = len(personas_data)\n",
    "total_prompt_tokens = prompt_per_persona * num_personas\n",
    "total_completion_tokens = completion_per_persona * num_personas\n",
    "\n",
    "# Get model from environment\n",
    "model = os.getenv(\"DEFAULT_MODEL\", \"gpt-4o\")\n",
    "\n",
    "# GPT-4o pricing (as of 2024): $2.50/1M input, $10/1M output\n",
    "PRICE_PER_1M_INPUT = 2.50\n",
    "PRICE_PER_1M_OUTPUT = 10.00\n",
    "\n",
    "estimated_cost = (\n",
    "    (total_prompt_tokens / 1_000_000) * PRICE_PER_1M_INPUT +\n",
    "    (total_completion_tokens / 1_000_000) * PRICE_PER_1M_OUTPUT\n",
    ")\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Model: {model}\")\n",
    "print(f\"  Personas: {num_personas}\")\n",
    "print(f\"  Files per persona: 2-5 (inferred based on occupation/age)\")\n",
    "\n",
    "print(f\"\\nPer-persona estimates (avg {AVG_FILES_PER_PERSONA} files):\")\n",
    "print(f\"  Prompt tokens: {prompt_per_persona:,.0f}\")\n",
    "print(f\"  Completion tokens: {completion_per_persona:,.0f}\")\n",
    "print(f\"  Total tokens: {prompt_per_persona + completion_per_persona:,.0f}\")\n",
    "\n",
    "print(f\"\\nTotal estimates ({num_personas} personas):\")\n",
    "print(f\"  Prompt tokens: {total_prompt_tokens:,.0f}\")\n",
    "print(f\"  Completion tokens: {total_completion_tokens:,.0f}\")  \n",
    "print(f\"  Total tokens: {total_prompt_tokens + total_completion_tokens:,.0f}\")\n",
    "print(f\"\\n  Estimated cost: ${estimated_cost:.2f} (GPT-4o pricing)\")\n",
    "print(f\"  With 20% safety margin: ${estimated_cost * 1.2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ifjh50o35q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File type inference preview:\n",
      "\n",
      "  Dilek Aydin (67, retired, Retired):\n",
      "    Education: No formal qualifications\n",
      "    -> Files: ['reading_list', 'shopping_history', 'spotify_favorites', 'charity_donations', 'bank_categories']\n",
      "  Kemal Aydin (43, electrician, Trades):\n",
      "    Education: Vocational/trade certificate\n",
      "    -> Files: ['bookmarks', 'pet_profile']\n",
      "  Zeynep Aydin (40, shop assistant, Retail):\n",
      "    Education: GCSEs\n",
      "    -> Files: ['bank_categories', 'cv', 'youtube_subscriptions', 'instagram_bio']\n",
      "  Hasan Aydin (20, student, Student):\n",
      "    Education: A-levels\n",
      "    -> Files: ['yelp_reviews', 'spotify_favorites', 'location_history', 'youtube_subscriptions', 'reddit_profile']\n",
      "  Emine Aydin (18, student, Student):\n",
      "    Education: A-levels\n",
      "    -> Files: ['travel_history', 'vehicle_info', 'spotify_favorites', 'home_description', 'shopping_history']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic files for each persona\n",
    "# Personas now include industry and education fields - direct SyntheticIdentity conversion\n",
    "\n",
    "import asyncio\n",
    "import random\n",
    "\n",
    "def persona_to_identity(p: dict) -> SyntheticIdentity:\n",
    "    \"\"\"Convert persona dict to SyntheticIdentity - now a simple field mapping.\"\"\"\n",
    "    return SyntheticIdentity(\n",
    "        name=p[\"name\"],\n",
    "        age=p[\"age\"],\n",
    "        gender=p[\"gender\"],\n",
    "        location=f\"{p['address'].split(',')[0]}, Dalston, London\",\n",
    "        occupation=p[\"occupation\"],\n",
    "        industry=p[\"industry\"],  # Direct from persona data\n",
    "        education=p[\"education\"],  # Direct from persona data\n",
    "        political_lean=p[\"political_lean\"],\n",
    "        personality_sketch=p[\"personality_sketch\"],\n",
    "    )\n",
    "\n",
    "\n",
    "# Preview file type inference for a few personas\n",
    "print(\"File type inference preview:\\n\")\n",
    "for p in personas_data[:5]:\n",
    "    identity = persona_to_identity(p)\n",
    "    num_files = random.randint(2, 5)\n",
    "    inferred_types = infer_file_types_for_identity(identity, num_files=num_files)\n",
    "    print(f\"  {p['name']} ({p['age']}, {p['occupation']}, {p['industry']}):\")\n",
    "    print(f\"    Education: {p['education']}\")\n",
    "    print(f\"    -> Files: {inferred_types}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "gi8gxsq29su",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona file generation status:\n",
      "  Already cached: 100\n",
      "  Need generation: 0\n",
      "\n",
      "✓ All 100 personas already have files. Skipping generation.\n"
     ]
    }
   ],
   "source": [
    "# Generate files for all personas\n",
    "# CACHING: Skips personas that already have generated files\n",
    "# File types are inferred per-person (2-5 files based on occupation/age)\n",
    "\n",
    "PERSONAS_DIR = Path('../data/synthetic/dalston_clt/personas')\n",
    "\n",
    "def persona_has_files(persona_id: str, output_base: Path) -> bool:\n",
    "    \"\"\"Check if persona already has generated files (at least identity.json + 1 other file).\"\"\"\n",
    "    persona_dir = output_base / persona_id\n",
    "    if not persona_dir.exists():\n",
    "        return False\n",
    "    has_identity = (persona_dir / \"identity.json\").exists()\n",
    "    has_data_files = any(f.suffix == \".txt\" for f in persona_dir.iterdir() if f.is_file())\n",
    "    return has_identity and has_data_files\n",
    "\n",
    "\n",
    "async def generate_files_for_persona(persona: dict, output_base: Path) -> tuple[str, dict, float]:\n",
    "    \"\"\"Generate files for a single persona. Returns (persona_id, saved_files, cost).\"\"\"\n",
    "    identity = persona_to_identity(persona)\n",
    "    \n",
    "    # Infer appropriate file types for this person (2-5 files)\n",
    "    num_files = random.randint(2, 5)\n",
    "    file_types = infer_file_types_for_identity(identity, num_files=num_files)\n",
    "    \n",
    "    persona_dir = output_base / persona[\"id\"]\n",
    "    \n",
    "    saved_files = await generate_synthetic_files(\n",
    "        identity=identity,\n",
    "        output_dir=persona_dir,\n",
    "        file_types=file_types,\n",
    "    )\n",
    "    \n",
    "    estimated_cost = len(saved_files) * 0.003\n",
    "    return persona[\"id\"], {k: str(v) for k, v in saved_files.items()}, estimated_cost\n",
    "\n",
    "\n",
    "# Create output directory\n",
    "PERSONAS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check which personas need generation\n",
    "personas_to_generate = [p for p in personas_data if not persona_has_files(p[\"id\"], PERSONAS_DIR)]\n",
    "personas_cached = [p[\"id\"] for p in personas_data if persona_has_files(p[\"id\"], PERSONAS_DIR)]\n",
    "\n",
    "print(f\"Persona file generation status:\")\n",
    "print(f\"  Already cached: {len(personas_cached)}\")\n",
    "print(f\"  Need generation: {len(personas_to_generate)}\")\n",
    "\n",
    "if not personas_to_generate:\n",
    "    print(f\"\\n✓ All {len(personas_cached)} personas already have files. Skipping generation.\")\n",
    "    results = [{\"persona_id\": pid, \"files\": \"cached\"} for pid in personas_cached]\n",
    "    total_cost = 0.0\n",
    "    errors = []\n",
    "else:\n",
    "    print(f\"\\nGenerating files for {len(personas_to_generate)} personas concurrently...\")\n",
    "    print(f\"Output directory: {PERSONAS_DIR}\")\n",
    "    print(f\"Files per persona: 2-5 (inferred based on occupation/age)\")\n",
    "    print()\n",
    "\n",
    "    results = [{\"persona_id\": pid, \"files\": \"cached\"} for pid in personas_cached]\n",
    "    total_cost = 0.0\n",
    "    errors = []\n",
    "    file_type_counts = {}\n",
    "\n",
    "    # Process ALL personas concurrently\n",
    "    tasks = [generate_files_for_persona(p, PERSONAS_DIR) for p in personas_to_generate]\n",
    "    all_results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    \n",
    "    for i, result in enumerate(all_results):\n",
    "        if isinstance(result, Exception):\n",
    "            persona_id = personas_to_generate[i][\"id\"]\n",
    "            errors.append((persona_id, str(result)))\n",
    "            print(f\"  ERROR: {persona_id}: {result}\")\n",
    "        else:\n",
    "            persona_id, saved_files, cost = result\n",
    "            results.append({\"persona_id\": persona_id, \"files\": saved_files})\n",
    "            total_cost += cost\n",
    "            for ft in saved_files.keys():\n",
    "                file_type_counts[ft] = file_type_counts.get(ft, 0) + 1\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FILE GENERATION COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Cached (skipped): {len(personas_cached)}\")\n",
    "    print(f\"  Newly generated: {len(personas_to_generate) - len(errors)}\")\n",
    "    print(f\"  Errors: {len(errors)}\")\n",
    "    print(f\"  Cost for new files: ${total_cost:.4f}\")\n",
    "    \n",
    "    if file_type_counts:\n",
    "        print(f\"\\n  File type distribution:\")\n",
    "        for ft, count in sorted(file_type_counts.items(), key=lambda x: -x[1]):\n",
    "            print(f\"    {ft}: {count}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nErrors:\")\n",
    "        for persona_id, error in errors[:10]:\n",
    "            print(f\"  {persona_id}: {error}\")\n",
    "        if len(errors) > 10:\n",
    "            print(f\"  ... and {len(errors) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sagpgcoh14r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample files for hh_001_p1:\n",
      "Directory: ../data/synthetic/dalston_clt/personas/hh_001_p1\n",
      "\n",
      "--- facebook_about.txt ---\n",
      "**About/Intro:**\n",
      "Hello, I'm Dilek! I'm a retired Londoner with a passion for gardening and cooking delicious Turkish meals for my loved ones. I enjoy being a part of my vibrant community here in Dalston and always love a good chat with friends and neighbors.\n",
      "\n",
      "**Work and Education:**\n",
      "- Occupation: Retired\n",
      "- Education: No formal qualifications\n",
      "\n",
      "**Relationship Status:**\n",
      "- Married\n",
      "\n",
      "**Places Lived:**\n",
      "- Originally from Turkey\n",
      "- Currently residing at 1 Hackett Green Road, Dalston, London\n",
      "\n",
      "**Life Events\n",
      "...[truncated]\n",
      "\n",
      "--- identity.json ---\n",
      "{\n",
      "  \"name\": \"Dilek Aydin\",\n",
      "  \"age\": 67,\n",
      "  \"gender\": \"female\",\n",
      "  \"location\": \"1 Hackett Green Road, Dalston, London\",\n",
      "  \"occupation\": \"retired\",\n",
      "  \"industry\": \"Retired\",\n",
      "  \"education\": \"No formal qualifications\",\n",
      "  \"political_lean\": \"neutral\",\n",
      "  \"personality_sketch\": \"Dilek enjoys tending to her small garden and cooking traditional Turkish meals for her family. She loves chatting with neighbors and keeps a keen eye on the happenings of the local community.\"\n",
      "}\n",
      "\n",
      "--- text_messages.txt ---\n",
      "**Conversation with Family Member (Child):**\n",
      "\n",
      "**Dilek**: Hi dear! 🌸 I found a new recipe for baklava, want to try it when you visit this weekend?\n",
      "\n",
      "**Child**: Sounds delicious, mum! Can't wait to taste it. What time should we come?\n",
      "\n",
      "**Dilek**: Let's say 2 PM? I'll have the tea ready.\n",
      "\n",
      "**Child**: Perfect! Bringing some ice cream too. See you then!\n",
      "\n",
      "**Dilek**: Wonderful! Safe travels. ❤️\n",
      "\n",
      "---\n",
      "\n",
      "**Conversation with Friend:**\n",
      "\n",
      "**Dilek**: Merhaba Ayse! 🌿 Did you see the roses in Mrs. Patel’s garden? Th\n",
      "...[truncated]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview generated files for a sample persona\n",
    "sample_persona_id = results[0][\"persona_id\"] if results else personas_data[0][\"id\"]\n",
    "sample_dir = PERSONAS_DIR / sample_persona_id\n",
    "\n",
    "print(f\"Sample files for {sample_persona_id}:\")\n",
    "print(f\"Directory: {sample_dir}\")\n",
    "print()\n",
    "\n",
    "for file_path in sorted(sample_dir.iterdir()):\n",
    "    if not file_path.is_file():  # Skip directories like .ipynb_checkpoints\n",
    "        continue\n",
    "    print(f\"--- {file_path.name} ---\")\n",
    "    content = file_path.read_text()\n",
    "    # Show first 500 chars\n",
    "    if len(content) > 500:\n",
    "        print(content[:500] + \"\\n...[truncated]\")\n",
    "    else:\n",
    "        print(content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2zvp4oqb5a",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 7: Extract Rich Context Statements\n",
    "\n",
    "Process the generated files through the extraction pipeline to create rich context statements for each persona. This uses the same `process_personal_folder` function used for real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eloivumydbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COST ESTIMATION: Context Extraction\n",
      "============================================================\n",
      "\n",
      "Personas to process: 100\n",
      "\n",
      "Per-persona estimates:\n",
      "  Prompt tokens: 3,300\n",
      "  Completion tokens: 700\n",
      "\n",
      "Total estimates:\n",
      "  Prompt tokens: 330,000\n",
      "  Completion tokens: 70,000\n",
      "\n",
      "  💰 Estimated cost: $1.53\n"
     ]
    }
   ],
   "source": [
    "# Cost estimation for context extraction\n",
    "print(\"=\" * 60)\n",
    "print(\"COST ESTIMATION: Context Extraction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count personas with generated files\n",
    "personas_with_files = list(PERSONAS_DIR.iterdir()) if PERSONAS_DIR.exists() else []\n",
    "num_to_process = len(personas_with_files)\n",
    "\n",
    "# Per-persona: profile extraction + context statement generation\n",
    "# These are the expensive operations\n",
    "context_prompt_tokens = EXTRACTION_PROMPT_TOKENS + CONTEXT_PROMPT_TOKENS  # ~3300\n",
    "context_completion_tokens = EXTRACTION_COMPLETION_TOKENS + CONTEXT_COMPLETION_TOKENS  # ~700\n",
    "\n",
    "total_context_prompt = context_prompt_tokens * num_to_process\n",
    "total_context_completion = context_completion_tokens * num_to_process\n",
    "\n",
    "# Calculate cost directly using token counts\n",
    "context_cost = (\n",
    "    (total_context_prompt / 1_000_000) * PRICE_PER_1M_INPUT +\n",
    "    (total_context_completion / 1_000_000) * PRICE_PER_1M_OUTPUT\n",
    ")\n",
    "\n",
    "print(f\"\\nPersonas to process: {num_to_process}\")\n",
    "print(f\"\\nPer-persona estimates:\")\n",
    "print(f\"  Prompt tokens: {context_prompt_tokens:,}\")\n",
    "print(f\"  Completion tokens: {context_completion_tokens:,}\")\n",
    "\n",
    "print(f\"\\nTotal estimates:\")\n",
    "print(f\"  Prompt tokens: {total_context_prompt:,}\")\n",
    "print(f\"  Completion tokens: {total_context_completion:,}\")\n",
    "print(f\"\\n  💰 Estimated cost: ${context_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "zbo662ycykf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 36 cached context statements from context_cache.json\n",
      "\n",
      "Context extraction status:\n",
      "  Already cached: 36\n",
      "  Need extraction: 64\n",
      "\n",
      "Extracting context statements for 64 personas concurrently...\n",
      "  ERROR: hh_024_p2: Failed to process hh_024_p2: 1 validation error for ExtractedProfile\n",
      "years_experience\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='null', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing\n",
      "\n",
      "============================================================\n",
      "CONTEXT EXTRACTION COMPLETE\n",
      "============================================================\n",
      "  Cached (skipped): 36\n",
      "  Newly extracted: 63\n",
      "  Errors: 1\n",
      "  Cost for new extractions: $0.6300\n",
      "\n",
      "  Cache saved to: ../data/synthetic/dalston_clt/context_cache.json\n",
      "\n",
      "Errors:\n",
      "  hh_024_p2: Failed to process hh_024_p2: 1 validation error for ExtractedProfile\n",
      "years_experience\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='null', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing\n"
     ]
    }
   ],
   "source": [
    "# Extract context statements for all personas\n",
    "# CACHING: Saves context statements to file and reuses them on rerun\n",
    "\n",
    "# Force reload of the extractors module to pick up any changes\n",
    "import importlib\n",
    "import centuria.data.extractors\n",
    "import centuria.data\n",
    "importlib.reload(centuria.data.extractors)\n",
    "importlib.reload(centuria.data)\n",
    "from centuria.data.extractors import process_personal_folder\n",
    "\n",
    "CONTEXT_CACHE_FILE = output_dir / 'context_cache.json'\n",
    "\n",
    "# Load existing cache if available\n",
    "if CONTEXT_CACHE_FILE.exists():\n",
    "    with open(CONTEXT_CACHE_FILE) as f:\n",
    "        context_cache = json.load(f)\n",
    "    print(f\"Loaded {len(context_cache)} cached context statements from {CONTEXT_CACHE_FILE.name}\")\n",
    "else:\n",
    "    context_cache = {}\n",
    "    print(\"No context cache found. Will generate all context statements.\")\n",
    "\n",
    "\n",
    "async def extract_context_for_persona(persona_id: str, persona_dir: Path) -> tuple[str, str, float]:\n",
    "    \"\"\"Extract context statement for a persona. Returns (persona_id, context_statement, cost).\"\"\"\n",
    "    try:\n",
    "        profile, context_statement = await process_personal_folder(str(persona_dir))\n",
    "        estimated_cost = 0.01\n",
    "        return persona_id, context_statement, estimated_cost\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to process {persona_id}: {e}\")\n",
    "\n",
    "\n",
    "# Get list of persona directories (filter out non-directories like .DS_Store)\n",
    "persona_dirs = sorted([d for d in PERSONAS_DIR.iterdir() if d.is_dir()]) if PERSONAS_DIR.exists() else []\n",
    "\n",
    "# Determine which need extraction\n",
    "dirs_to_process = [d for d in persona_dirs if d.name not in context_cache]\n",
    "\n",
    "print(f\"\\nContext extraction status:\")\n",
    "print(f\"  Already cached: {len(persona_dirs) - len(dirs_to_process)}\")\n",
    "print(f\"  Need extraction: {len(dirs_to_process)}\")\n",
    "\n",
    "# Start with cached results\n",
    "context_results = dict(context_cache)\n",
    "extraction_errors = []\n",
    "extraction_cost = 0.0\n",
    "\n",
    "if not dirs_to_process:\n",
    "    print(f\"\\n✓ All {len(context_results)} context statements cached. Skipping extraction.\")\n",
    "else:\n",
    "    print(f\"\\nExtracting context statements for {len(dirs_to_process)} personas concurrently...\")\n",
    "    \n",
    "    # Process ALL personas concurrently\n",
    "    tasks = [extract_context_for_persona(d.name, d) for d in dirs_to_process]\n",
    "    all_results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    \n",
    "    for i, result in enumerate(all_results):\n",
    "        if isinstance(result, Exception):\n",
    "            persona_id = dirs_to_process[i].name\n",
    "            extraction_errors.append((persona_id, str(result)))\n",
    "            print(f\"  ERROR: {persona_id}: {result}\")\n",
    "        else:\n",
    "            persona_id, context_statement, cost = result\n",
    "            context_results[persona_id] = context_statement\n",
    "            extraction_cost += cost\n",
    "\n",
    "    # Save cache\n",
    "    with open(CONTEXT_CACHE_FILE, 'w') as f:\n",
    "        json.dump(context_results, f, indent=2)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"CONTEXT EXTRACTION COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Cached (skipped): {len(persona_dirs) - len(dirs_to_process)}\")\n",
    "    print(f\"  Newly extracted: {len(dirs_to_process) - len(extraction_errors)}\")\n",
    "    print(f\"  Errors: {len(extraction_errors)}\")\n",
    "    print(f\"  Cost for new extractions: ${extraction_cost:.4f}\")\n",
    "    print(f\"\\n  Cache saved to: {CONTEXT_CACHE_FILE}\")\n",
    "\n",
    "    if extraction_errors:\n",
    "        print(f\"\\nErrors:\")\n",
    "        for persona_id, error in extraction_errors[:10]:\n",
    "            print(f\"  {persona_id}: {error}\")\n",
    "        if len(extraction_errors) > 10:\n",
    "            print(f\"  ... and {len(extraction_errors) - 10} more\")\n",
    "\n",
    "num_to_process = len(context_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5ihlgu89fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample context statements:\n",
      "\n",
      "============================================================\n",
      "Kemal Aydin (hh_001_p2)\n",
      "============================================================\n",
      "This individual resides in the United Kingdom and falls within the 30-35 age range. They are currently employed as an electrician in the electrical industry. Although their years of experience and educational background are unspecified, their professional activities are likely supported by key skills in electrical work, DIY, and fitness. This person appears to value practicality and organization in their work, as suggested by their analytical communication style and an independent work approach combined with a moderate risk tolerance. Continuous learning also seems to be a core value, as indicated by their active engagement in understanding their trade and advancements in related fields.\n",
      "\n",
      "Their intellectual interests span engineering, technology, and history, which aligns with their consum\n",
      "...[truncated]\n",
      "\n",
      "============================================================\n",
      "Zeynep Aydin (hh_001_p3)\n",
      "============================================================\n",
      "This individual’s profile presents limited information about their work and educational background. There is no specific data provided about their current role, industry, or years of experience in any field. Additionally, there is no detailed information about their education level or field of study.\n",
      "\n",
      "Their intellectual interests include music and culinary arts. This is reflected in their choice of reading and media consumption, which includes genres such as cooking and fantasy for reading materials, and an emphasis on music and books in their media diet. Their preferred music artists consist of soul, folk, and jazz musicians like Adele, Florence + The Machine, Alicia Keys, and Norah Jones, among others. Their playlists include themes such as \"Sunday Morning Chill\" and \"Dinner Party Vibes,\n",
      "...[truncated]\n",
      "\n",
      "============================================================\n",
      "Hasan Aydin (hh_001_p4)\n",
      "============================================================\n",
      "Hasan Aydin is a student currently pursuing a bachelor's degree in Computer Science. His involvement in the technology industry is primarily academic, and he has not reported any specific work experience. Hasan's key skills include programming, debating, and gaming, suggesting a combination of technical knowledge and communication ability.\n",
      "\n",
      "Hasan's intellectual interests are diverse yet centered around technology and digital media. He has a strong interest in both technology and gaming, evident in his media consumption, which includes tech blogs, gaming content, memes, and tech magazines. His reading preferences align with these interests, focusing on technology and programming genres. This suggests that his knowledge and interests are continuously enriched by current technological advance\n",
      "...[truncated]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview some context statements\n",
    "print(\"Sample context statements:\\n\")\n",
    "\n",
    "sample_ids = list(context_results.keys())[:3]\n",
    "for persona_id in sample_ids:\n",
    "    # Find persona name\n",
    "    persona = next((p for p in personas_data if p[\"id\"] == persona_id), None)\n",
    "    name = persona[\"name\"] if persona else persona_id\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"{name} ({persona_id})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    context = context_results[persona_id]\n",
    "    # Show first 800 chars\n",
    "    if len(context) > 800:\n",
    "        print(context[:800] + \"\\n...[truncated]\")\n",
    "    else:\n",
    "        print(context)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kaepqgjhuz",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 8: Export Final Personas\n",
    "\n",
    "Combine the original persona data with the rich context statements and export for use in the Testing space before it happens experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29aft6da0vn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona enrichment summary:\n",
      "  Total personas: 100\n",
      "  With rich context: 99\n",
      "  Fallback context: 1\n"
     ]
    }
   ],
   "source": [
    "# Combine persona data with rich context statements\n",
    "enriched_personas = []\n",
    "\n",
    "for persona in personas_data:\n",
    "    persona_id = persona[\"id\"]\n",
    "    \n",
    "    # Get the rich context statement if available\n",
    "    if persona_id in context_results:\n",
    "        rich_context = context_results[persona_id]\n",
    "    else:\n",
    "        # Fallback to basic context from original data\n",
    "        rich_context = f\"{persona['personality_sketch']} Lives at {persona['address']}. Works as {persona['occupation']}. Political lean: {persona['political_lean']}.\"\n",
    "    \n",
    "    enriched_persona = {\n",
    "        **persona,  # Keep all original fields\n",
    "        \"rich_context\": rich_context,\n",
    "        \"has_synthetic_files\": persona_id in context_results,\n",
    "    }\n",
    "    enriched_personas.append(enriched_persona)\n",
    "\n",
    "# Count enriched vs fallback\n",
    "enriched_count = sum(1 for p in enriched_personas if p[\"has_synthetic_files\"])\n",
    "fallback_count = len(enriched_personas) - enriched_count\n",
    "\n",
    "print(f\"Persona enrichment summary:\")\n",
    "print(f\"  Total personas: {len(enriched_personas)}\")\n",
    "print(f\"  With rich context: {enriched_count}\")\n",
    "print(f\"  Fallback context: {fallback_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bxqicjwk19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 100 enriched personas to ../data/synthetic/dalston_clt/personas_enriched.json\n",
      "Exported 100 web-ready personas to ../data/synthetic/dalston_clt/personas_for_survey.json\n"
     ]
    }
   ],
   "source": [
    "# Export enriched personas\n",
    "output_file = output_dir / 'personas_enriched.json'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(enriched_personas, f, indent=2)\n",
    "\n",
    "print(f\"Exported {len(enriched_personas)} enriched personas to {output_file}\")\n",
    "\n",
    "# Also export a simplified version for the web experiment\n",
    "# Just id, name, and rich_context\n",
    "web_personas = [\n",
    "    {\n",
    "        \"id\": p[\"id\"],\n",
    "        \"name\": p[\"name\"],\n",
    "        \"age\": p[\"age\"],\n",
    "        \"gender\": p[\"gender\"],\n",
    "        \"occupation\": p[\"occupation\"],\n",
    "        \"ethnicity\": p[\"ethnicity\"],\n",
    "        \"address\": p[\"address\"],\n",
    "        \"context\": p[\"rich_context\"],\n",
    "    }\n",
    "    for p in enriched_personas\n",
    "]\n",
    "\n",
    "web_output = output_dir / 'personas_for_survey.json'\n",
    "with open(web_output, 'w') as f:\n",
    "    json.dump(web_personas, f, indent=2)\n",
    "\n",
    "print(f\"Exported {len(web_personas)} web-ready personas to {web_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3qez8knba7h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PIPELINE COMPLETE\n",
      "============================================================\n",
      "\n",
      "Generated files:\n",
      "  ../data/synthetic/dalston_clt/personas_enriched.json\n",
      "  ../data/synthetic/dalston_clt/personas_for_survey.json\n",
      "  ../data/synthetic/dalston_clt/personas/ (individual persona folders)\n",
      "\n",
      "Context statement statistics:\n",
      "  Average length: 2729 characters\n",
      "  Min length: 459 characters\n",
      "  Max length: 3136 characters\n",
      "\n",
      "Sample persona for survey use:\n",
      "  Name: Dilek Aydin\n",
      "  Age: 67\n",
      "  Occupation: retired\n",
      "  Context preview: Dilek is a retired individual residing in Dalston, London. She originally hails from Turkey and moved to London in 1985. Dilek has two children, born in 1980 and 1983, and she has been married since 1...\n"
     ]
    }
   ],
   "source": [
    "# Final summary and statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Context statement length statistics\n",
    "context_lengths = [len(p[\"rich_context\"]) for p in enriched_personas]\n",
    "avg_length = sum(context_lengths) / len(context_lengths)\n",
    "min_length = min(context_lengths)\n",
    "max_length = max(context_lengths)\n",
    "\n",
    "print(f\"\\nGenerated files:\")\n",
    "print(f\"  {output_dir / 'personas_enriched.json'}\")\n",
    "print(f\"  {output_dir / 'personas_for_survey.json'}\")\n",
    "print(f\"  {PERSONAS_DIR}/ (individual persona folders)\")\n",
    "\n",
    "print(f\"\\nContext statement statistics:\")\n",
    "print(f\"  Average length: {avg_length:.0f} characters\")\n",
    "print(f\"  Min length: {min_length} characters\")\n",
    "print(f\"  Max length: {max_length} characters\")\n",
    "\n",
    "print(f\"\\nSample persona for survey use:\")\n",
    "sample = enriched_personas[0]\n",
    "print(f\"  Name: {sample['name']}\")\n",
    "print(f\"  Age: {sample['age']}\")\n",
    "print(f\"  Occupation: {sample['occupation']}\")\n",
    "print(f\"  Context preview: {sample['rich_context'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tfokn4vopmd",
   "metadata": {},
   "source": [
    "---\n",
    "## Usage Example\n",
    "\n",
    "How to use these personas in a survey (e.g., for Testing space before it happens):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6j7x9wduqsp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create Persona objects for surveying\n",
    "from centuria.models import Persona, Question\n",
    "from centuria.persona import create_persona\n",
    "from centuria.survey import ask_question\n",
    "\n",
    "# Load the enriched personas\n",
    "with open('../data/synthetic/dalston_clt/personas_for_survey.json') as f:\n",
    "    survey_personas_data = json.load(f)\n",
    "\n",
    "# Create Persona objects\n",
    "survey_personas = [\n",
    "    create_persona(\n",
    "        name=p['name'],\n",
    "        context=p['context'],\n",
    "        persona_id=p['id']\n",
    "    )\n",
    "    for p in survey_personas_data\n",
    "]\n",
    "\n",
    "print(f\"Created {len(survey_personas)} Persona objects for surveying\")\n",
    "\n",
    "# Example question for the Testing space before it happens experiment\n",
    "garden_question = Question(\n",
    "    id=\"garden_priority\",\n",
    "    text=\"A 0.3-acre plot of land near your home has become available for community use. What would be your top priority for how this space should be used?\",\n",
    "    question_type=\"single_select\",\n",
    "    options=[\n",
    "        \"Community garden for growing food\",\n",
    "        \"Green space with trees and benches\",\n",
    "        \"Children's playground\",\n",
    "        \"Wildlife habitat / nature reserve\",\n",
    "        \"Community events space\",\n",
    "        \"Allotments for residents\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Test with first 3 personas\n",
    "print(\"\\nSample responses to garden question:\\n\")\n",
    "for persona in survey_personas[:3]:\n",
    "    response = await ask_question(persona, garden_question)\n",
    "    print(f\"{persona.name}: {response.response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aabf70-d288-4541-b7da-ab4cb8bbc8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
